{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUSSINESS AND DATA UNDERSTANDING\n",
    "\n",
    "Este notebook esta destinado a cubrir las dos primeras fases estipulada en la metodología  CRISP-DM (Cross Industry Standard Process for Data Mining).\n",
    "\n",
    "La metodología se divide en las siguientes: \n",
    "\n",
    "1. <span style=\"color:green;\">[**Comprensión del Negocio (Business Understanding)**](#business-understanding)</span>  \n",
    "   - Consistente en el entendimiento del objetivo del proyecto.\n",
    "\n",
    "2. <span style=\"color:green;\">[**Comprensión de los Datos (Data Understanding)**](#data-understanding)</span>  \n",
    "   - Relacionada con la carga y primera evaluación del conjunto de datos.\n",
    "\n",
    "3. **Preparación de los Datos (Data Preparation)**  \n",
    "   - Consistente en la limpieza, preparación y extracción de características de los datos.\n",
    "\n",
    "4. **Modelado (Modeling)**  \n",
    "   - Relacionada con la elección del modelo de machine learning y el ajuste hiperparamétrico.\n",
    "\n",
    "5. **Evaluación (Evaluation)**  \n",
    "   - Evaluación de los resultados obtenidos por el modelo.\n",
    "\n",
    "6. **Implementación (Deployment)**  \n",
    "   - Integración del modelo de forma que sea accesible para su uso.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"business-understanding\"></a>\n",
    "\n",
    "## 1. Business understanding\n",
    "\n",
    "El problema a tratar se trata de la obtención de descripciones de las escenas a partir de los cotidianos presentes en las mismas, con enfasis en aquellos elementos que sean especialmente relevantes para la mejora de la accesibilidad en personas con discapacidad visual, \n",
    "\n",
    "\n",
    "Es por ello que podemos definir este problema como uno de **segmentación semántica**, al ser necesaria la obtención de regiones dentro de una imagen de entrada que se correspondan con los objetos a detectar, de tal forma que cada uno de los píxeles de esta quede clasificado como una clase de un conjunto de clases finito, diferenciandose así de  otros problemas como el de clasificación de imágenes, donde se asigna una etiqueta o categoría a la imagen de forma global, el de detección, donde se localizan objetos delimitandolos por cajas o bounding boxes, o el de segmentación de instancias, que identifica cada instancia de cada objeto de forma separada. Un ejemplo práctico cada uno de los problemas anteriores se observa en la figura siguiente:\n",
    "\n",
    "\n",
    "<img src=\"./../assets/figs/problema.png\" alt=\"Problema a resolver\" style=\"width: 50%; height: auto;\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-understanding\"></a>\n",
    "\n",
    "## 2. Data understanding\n",
    "\n",
    "Una vez definido el problema, se procede a la carga del conjunto de datos.\n",
    "\n",
    "Esta etapa se divide en hasta 4 fases:\n",
    "\n",
    "1. Descarga del conjunto de datos\n",
    "2. Análisis exploratorio del conjunto de datos\n",
    "3. Sampling del conjunto de datos\n",
    "4. Extracción de características\n",
    "\n",
    "\n",
    "Para una mejor organización, en este notebook, se abordará la primera de las 4 fases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se ha decidido hacer uso del dataset `MS COCO` en su más reciente actualización, que data del 2017, siendo posible acceder a su documentación en el siguiente [enlace](https://cocodataset.org/#home), frente a otros datasets como `ADE20K`, en parte gracias a su alto volumen de datos y mayor variedad de clases etiquetadas, por ser más facil de moldar al caso de uso definido.\n",
    "\n",
    "Este dataset destaca por contener, en su versión mas reciente, hasta un total de casi 200.000 imágenes, en las cuales se encuentran hasta un total de 1.5 millones de objetos diferentes segmentados de hasta un total de 80 clases diferetes. Fue propuesto por Microsoft en 2014 y actualizado en 2017 y puede ser utilizado para resolver problemas de detección de objetos, segmentación semántica y segmentación de instancias, además de contener keypoints de las 17 partes del cuerpo humano más relevante para la detección de poses. Cabe destacar una gran variedad de resoluciones de las imágenes, fuentes de datos de su obtención, al ser obtenidas a partir de plataformas como Flickr y de una variedad de geografías, que hacen que ayudan a que el entrenamiento de un modelo con este conjunto de datos pueda generalizar mejor.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen dos formas de cargarlo en memoria, por un lado puede ser cargado a disco directamente descargando los datos de su web, o bien a partir de la libreria `tensorflow_datasets`, que dejará el dataset almacenado en memorai de forma temporal.\n",
    "\n",
    "\n",
    "Podemos almacenarlo de forma permanente de la siguiente manera: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'c:\\\\Users\\\\ruben\\\\Desktop\\\\code_tfm\\\\src\\\\utils.py'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import utils\n",
    "\n",
    "# refresca la cache para la carga adecuada del fichero utils, donde no siempre captura bien las funciones\n",
    "importlib.reload(utils)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from utils import  load_yaml_file, download_zip\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cargan las constantes necesarias definidas en el YALM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = load_yaml_file()\n",
    "\n",
    "# Constantes relativas a la direccion destino de la carga de imagenes del dataset\n",
    "\n",
    "DIR_IMGS_DATASET_RAW = yaml[\"dir_datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ruben\\\\Desktop\\\\code_tfm\\\\dataset\\\\coco'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Nos colocamos en la raiz para que el path sea el adecuado\n",
    "\n",
    "DIR_IMGS_DATASET_RAW \n",
    "dir_data_load = os.path.join(os.getcwd(),\"..\",DIR_IMGS_DATASET_RAW)\n",
    "dir_data_load = os.path.normpath(dir_data_load)\n",
    "dir_data_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a la descarga automatizada de estos en los directorios destino, junto con sus archivos de anotación correspondiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "segments = True  # True: se incluye la segmentacion, al tratar de resolverse un problema de segmentación y no de detección \n",
    "\n",
    "dir = Path(DIR_IMGS_DATASET_RAW)  \n",
    "\n",
    "URL_BASE = 'https://github.com/ultralytics/assets/releases/download/v0.0.0/'\n",
    "\n",
    "# Fichero usado para obtener las labels\n",
    "urls = [URL_BASE + ('coco2017labels-segments.zip' if segments else 'coco2017labels.zip')]\n",
    "# Imágenes\n",
    "urls += [\n",
    "    'http://images.cocodataset.org/zips/train2017.zip',\n",
    "    'http://images.cocodataset.org/zips/val2017.zip',\n",
    "    'http://images.cocodataset.org/zips/test2017.zip',\n",
    "]\n",
    "\n",
    "destinos = [DIR_IMGS_DATASET_RAW + nombre_destino for  nombre_destino in [\"segments\", \"train\", \"val\", \"test\"] ]\n",
    "filenames = [\"segments.zip\",\"train2017.zip\", \"val2017.zip\", \"test2017.zip\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://github.com/ultralytics/assets/releases/download/v0.0.0/coco2017labels-segments.zip',\n",
       " 'http://images.cocodataset.org/zips/train2017.zip',\n",
       " 'http://images.cocodataset.org/zips/val2017.zip',\n",
       " 'http://images.cocodataset.org/zips/test2017.zip']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se procede a la descarga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url, destino, nombre in zip(urls, destinos, filenames):\n",
    "    print(\"iterating over\",url, destino, nombre)\n",
    "    download_zip(url, destino, nombre)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se carga alguna imagen para comprobar la carga correcta del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.colors as colors\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from random import shuffle\n",
    "from PIL import Image\n",
    "\n",
    "from pycocotools.coco import COCO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='../datasets/coco/'\n",
    "dataType='val2017'\n",
    "annFile='{}annotations/instances_{}.json'.format(dataDir,dataType)\n",
    "imageDir = '{}/images/{}/'.format(dataDir, dataType)\n",
    "\n",
    "# Initialize the COCO api for instance annotations\n",
    "coco=COCO(annFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load categories for the given ids\n",
    "ids = 1\n",
    "cats = coco.loadCats(ids=ids)\n",
    "print(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_ids = coco.getCatIds()\n",
    "num_categories = len(category_ids)\n",
    "print('number of categories: ',num_categories)\n",
    "for ids in category_ids:\n",
    "    cats = coco.loadCats(ids=ids)\n",
    "    print(cats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images for the given ids\n",
    "image_ids = coco.getImgIds()\n",
    "image_id = image_ids[0]  # Change this line to display a different image\n",
    "image_info = coco.loadImgs(image_id)\n",
    "print(image_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations for the given ids\n",
    "annotation_ids = coco.getAnnIds(imgIds=image_id)\n",
    "annotations = coco.loadAnns(annotation_ids)\n",
    "print(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get category ids that satisfy the given filter conditions\n",
    "filterClasses = ['laptop', 'tv', 'cell phone']\n",
    "# Fetch class IDs only corresponding to the filterClasses\n",
    "catIds = coco.getCatIds(catNms=filterClasses)\n",
    "print(catIds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load category information for the given ID\n",
    "catID = 15\n",
    "print(coco.loadCats(ids=catID))\n",
    "\n",
    "# Get image ID that satisfies the given filter conditions\n",
    "imgId = coco.getImgIds(catIds=[catID])[0]\n",
    "print(imgId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catID = 15\n",
    "print(coco.loadCats(ids=catID))\n",
    "\n",
    "# Get image ids that satisfy the given filter conditions\n",
    "imgId = coco.getImgIds(catIds=[catID])[0]\n",
    "print(imgId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_ids = coco.getAnnIds(imgIds=[imgId], iscrowd=None)\n",
    "print(ann_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Annotations for Image ID {imgId}:\")\n",
    "anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "image_path = coco.loadImgs(imgId)[0]['file_name']\n",
    "print(image_path)\n",
    "image = plt.imread(imageDir + image_path)\n",
    "plt.imshow(image)\n",
    "\n",
    "# Display the specified annotations\n",
    "coco.showAnns(anns, draw_bbox=True)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.title('Annotations for Image ID: {}'.format(image_id))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comprueba tambien que la carga de los segmentos ha sido la adecuada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
