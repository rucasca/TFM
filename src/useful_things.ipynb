{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator():\n",
    "    for _ in range(1000):  # Example: 1000 samples\n",
    "        image = np.random.rand(256, 256, 3).astype(np.float32)  # RGB Image\n",
    "        mask = np.random.randint(0, 2, (256, 256, 1), dtype=np.uint8)  # Binary mask\n",
    "        yield image, mask\n",
    "\n",
    "# Create dataset using from_generator\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),  # Image shape\n",
    "        tf.TensorSpec(shape=(256, 256, 1), dtype=tf.uint8)     # Mask shape\n",
    "    )\n",
    ")\n",
    "\n",
    "# Optimize dataset performance\n",
    "dataset = (dataset\n",
    "    .shuffle(1000)  # Shuffle buffer\n",
    "    .batch(16)  # Batch size\n",
    "    .prefetch(tf.data.AUTOTUNE)  # Prefetch for fast training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data generator\n",
    "def data_generator():\n",
    "    for x, y in zip(X_list, Y_list):\n",
    "        yield x, y\n",
    "\n",
    "# Create dataset\n",
    "BATCH_SIZE = 16\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_generator,\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=(256, 256, 3), dtype=tf.float32),  # Image\n",
    "        tf.TensorSpec(shape=(256, 256, 4), dtype=tf.float32)   # One-hot mask (4 classes)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Optimize dataset pipeline\n",
    "dataset = dataset.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Model\n",
    "\n",
    "def unet_multiclass(input_shape=(256, 256, 3), num_classes=4):\n",
    "    inputs = layers.Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D((2, 2))(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = layers.MaxPooling2D((2, 2))(conv3)\n",
    "\n",
    "    # Bottleneck\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "\n",
    "    # Decoder\n",
    "    up5 = layers.UpSampling2D((2, 2))(conv4)\n",
    "    merge5 = layers.concatenate([conv3, up5], axis=-1)\n",
    "    conv5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(merge5)\n",
    "    conv5 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = layers.UpSampling2D((2, 2))(conv5)\n",
    "    merge6 = layers.concatenate([conv2, up6], axis=-1)\n",
    "    conv6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(merge6)\n",
    "    conv6 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = layers.UpSampling2D((2, 2))(conv6)\n",
    "    merge7 = layers.concatenate([conv1, up7], axis=-1)\n",
    "    conv7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(merge7)\n",
    "    conv7 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    # Output layer for multi-class segmentation\n",
    "    outputs = layers.Conv2D(num_classes, (1, 1), activation='softmax')(conv7)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Create model\n",
    "model = unet_multiclass()\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy', iou_metric])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Training settings\n",
    "EPOCHS = 50\n",
    "CHECKPOINT_PATH = \"best_unet_multiclass.h5\"\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(CHECKPOINT_PATH, monitor=\"val_loss\", save_best_only=True, mode=\"min\", verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-6, verbose=1),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=7, restore_best_weights=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    dataset, \n",
    "    epochs=EPOCHS, \n",
    "    validation_data=val_dataset,  # Assuming you have a validation dataset\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def iou_metric(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the mean Intersection over Union (IoU) for multi-class segmentation.\n",
    "    \"\"\"\n",
    "    y_pred = tf.argmax(y_pred, axis=-1)  # Convert softmax probabilities to class labels\n",
    "    y_true = tf.argmax(y_true, axis=-1)  # Convert one-hot to class labels\n",
    "    \n",
    "    iou_list = []\n",
    "    num_classes = tf.reduce_max(y_true) + 1  # Get number of classes dynamically\n",
    "    \n",
    "    for i in range(num_classes):\n",
    "        true_mask = tf.cast(y_true == i, tf.float32)\n",
    "        pred_mask = tf.cast(y_pred == i, tf.float32)\n",
    "\n",
    "        intersection = tf.reduce_sum(true_mask * pred_mask)\n",
    "        union = tf.reduce_sum(true_mask) + tf.reduce_sum(pred_mask) - intersection\n",
    "\n",
    "        iou = (intersection + 1e-6) / (union + 1e-6)  # Avoid division by zero\n",
    "        iou_list.append(iou)\n",
    "\n",
    "    return tf.reduce_mean(iou_list)  # Average IoU across classes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1 - 1e-7)  # Avoid zero division\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    \n",
    "    dice = (2. * intersection + 1e-6) / (union + 1e-6)\n",
    "    return 1 - tf.reduce_mean(dice)\n",
    "\n",
    "# Compile model with Dice Loss\n",
    "model.compile(optimizer='adam', loss=dice_loss, metrics=['accuracy', iou_metric])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_ce_loss(y_true, y_pred):\n",
    "    return 0.5 * dice_loss(y_true, y_pred) + 0.5 * tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "# Compile model with hybrid loss\n",
    "model.compile(optimizer='adam', loss=dice_ce_loss, metrics=['accuracy', iou_metric])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Example: Assigning weights to 4 classes\n",
    "class_weights = tf.constant([0.1, 0.3, 0.3, 0.3])  # Adjust based on dataset distribution\n",
    "\n",
    "def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Apply per-class weights\n",
    "    weights = tf.reduce_sum(class_weights * y_true, axis=-1)\n",
    "    weighted_loss = loss * weights\n",
    "    \n",
    "    return tf.reduce_mean(weighted_loss)\n",
    "\n",
    "# Compile model with WCCE\n",
    "model.compile(optimizer='adam', loss=weighted_categorical_crossentropy, metrics=['accuracy', iou_metric])\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
